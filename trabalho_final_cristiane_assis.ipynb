{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5447bfbb-1662-43fe-b728-099082ce33ca",
   "metadata": {},
   "source": [
    "# Avaliação de aprendizagem - Cristiane Lopes de Assis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4e0a0-f895-43c5-9a89-68412205aec2",
   "metadata": {},
   "source": [
    "## Desenvolvimento de um Chatbot com Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af4eaf-3751-4243-8866-db614791e0fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b697de-d922-40ec-aa79-0d509a3dfa95",
   "metadata": {},
   "source": [
    "Atualmente, atuo na Diretoria de Participação Digital e Comunicação em Rede da Secretaria Nacional de Participação Social da Secretaria-Geral da Presidência. Esta diretoria é responsável pelo gerenciamento da plataforma de participação social do governo federal Brasil Participativo. Seu objetivo é possibilitar que toda a população brasileira possa participar na elaboração, monitoramento e aperfeiçoamento de políticas públicas, em um canal único e direto com todo o governo federal, por meio de consultas públicas.\n",
    "\n",
    "A plataforma possui um chatbot. No entanto, ele funciona com perguntas pré-definidas e limitadas. O objetivo da atividade é ampliar o atendimento, possibilitando ao usuários sanar as suas dúvidas sobre participação social, sobre a plataforma e sobre os processos participativos ativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b959d46-f1fd-4631-ad54-10cf9d485472",
   "metadata": {},
   "source": [
    "### Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12b65f-b1fd-4b5b-a933-8b32f0650477",
   "metadata": {},
   "source": [
    "Para possibilitar a ampliação das possibilidade de interação, foi utilizado um documento em excel com a lista das principais dúvidas dos usuários sobre a plataforma e uma tabela em excel com os detalhes de todos os processos cadastrados.\n",
    "\n",
    "Além disso, foi integrado ao chat bot o modelo pré-treinado gemini-1.5-flash.\n",
    "\n",
    "A interface escolhida foi a da biblioteca streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f3d54-06f5-4ff7-88b6-eccce4e415e8",
   "metadata": {},
   "source": [
    "### Funcionamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf519b-e8ae-4480-8f79-ddb83975e21f",
   "metadata": {},
   "source": [
    "Para interação com o chat bot o usuário deve escrever sua dúvida na caixa e clicar em \"Digite aqui a sua dúvida sobre a plataforma Brasil Participativo e seus processos participativos\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334c283-0532-4eba-97a7-01230d5cea54",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5276a5b-6630-4ad9-91cc-663532759b5c",
   "metadata": {},
   "source": [
    "Espera-se que o usuário consiga sanar suas dúvidas e contribuir com os processos participativos ativos. O que trará mais engajamento para a plataforma, para os processos participativos e, no longo prazo, melhoria das políticas públicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa6c3f-7244-4a4c-8b0b-ec95dbc19c99",
   "metadata": {},
   "source": [
    "## Código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4708e309-83e6-4a34-9059-ab7333ae3b97",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ead50ff-b026-486d-8fe1-defebfb35c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 569 0 (offset 0)\n",
      "C:\\Users\\mauri\\AppData\\Local\\Temp\\ipykernel_19768\\635846133.py:58: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d155ac3fbff146579c197d8dd6de5f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 21:08:29.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.424 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.425 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.427 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.428 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.429 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.430 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.432 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.433 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.435 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-07 21:08:29.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import sys\n",
    "from importlib import util\n",
    "\n",
    "# Verificação das dependências\n",
    "def check_package(package_name):\n",
    "    if util.find_spec(package_name) is None:\n",
    "        st.error(f\"Pacote {package_name} não encontrado. Instale com: pip install {package_name}\")\n",
    "        st.stop()\n",
    "\n",
    "check_package(\"sentence_transformers\")\n",
    "check_package(\"transformers\")\n",
    "check_package(\"torch\")\n",
    "\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# Verificação rigorosa das dependências\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    from langchain.vectorstores import FAISS\n",
    "except ImportError as e:\n",
    "    st.error(f\"ERRO CRÍTICO: Falha na importação de dependências. Execute:\\n\\n\"\n",
    "             f\"pip uninstall -y numpy transformers sentence-transformers torch\\n\"\n",
    "             f\"pip install numpy==1.23.5 torch==2.0.1 transformers==4.30.2 sentence-transformers==2.2.2\")\n",
    "    st.stop()\n",
    "\n",
    "# Configurar a chave da API\n",
    "genai.configure(api_key=\"AIzaSyD6dpEEUjrKLNqO8XmrzqMUf5nvn4g8Cn0\")  # Substitua pela sua chave\n",
    "\n",
    "# Criar o modelo\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Você é um assistente virtual especializado em participação social. Ao receber uma mensagem, sua tarefa é:\n",
    "1. Fornecer respostas claras e objetivas sobre participação social e sobre a plataforma Brasil Participativo.\n",
    "2. Recomendar a participação social e, caso solicitado, sugira processos participativos abertos na plataforma Brasil Participativo.\n",
    "3. Não comente sobre o documento fornecido.\n",
    "4. Utilizar informações do documento PDF carregado para enriquecer suas respostas quando relevante.\n",
    "5. Seja educado!\n",
    "\"\"\"\n",
    "\n",
    "def setup_rag():\n",
    "    try:\n",
    "        if not os.path.exists(\"FAQ.docx.pdf\"):\n",
    "            return None\n",
    "        \n",
    "        pdf_loader = PyPDFLoader(\"FAQ.docx.pdf\")\n",
    "        documents = pdf_loader.load()\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=500)\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        \n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        db = FAISS.from_documents(texts, embeddings)\n",
    "        \n",
    "        return db\n",
    "    except Exception as e:\n",
    "        st.error(f\"Erro ao configurar RAG: {e}\")\n",
    "        return None\n",
    "\n",
    "vectorstore = setup_rag()\n",
    "\n",
    "def get_relevant_info(query):\n",
    "    if vectorstore is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        docs = vectorstore.similarity_search(query, k=2)\n",
    "        return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    except Exception as e:\n",
    "        st.error(f\"Erro na busca de informações: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_response(user_input, history):\n",
    "    relevant_info = get_relevant_info(user_input)\n",
    "    \n",
    "    prompt = system_prompt\n",
    "    if relevant_info:\n",
    "        prompt += f\"\\n\\nInformações relevantes do documento:\\n{relevant_info}\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content([f\"{history}\\nUsuário: {user_input}\\nAssistente:\", prompt])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao gerar resposta: {e}\"\n",
    "\n",
    "# Interface\n",
    "st.set_page_config(page_title=\"Chatbot - Plataforma Brasil Participativo\", page_icon=\"🤖\")\n",
    "st.title(\"🤖Chatbot - Plataforma Brasil Participativo 🤝\")\n",
    "\n",
    "# Histórico de conversa\n",
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = system_prompt\n",
    "if \"conversation\" not in st.session_state:\n",
    "    st.session_state.conversation = \"\"\n",
    "\n",
    "# Chat\n",
    "user_input = st.text_input(\"Digite sua dúvida sobre participação social e sobre a plataforma Brasil Participativo:\")\n",
    "if st.button(\"Enviar\") and user_input.strip():\n",
    "    st.session_state.conversation += f\"\\nUsuário: {user_input}\"\n",
    "    response = generate_response(user_input, st.session_state.conversation)\n",
    "    st.write(f\"**Assistente**: {response}\")\n",
    "    st.session_state.conversation += f\"\\nAssistente: {response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845bce0d-d1aa-4be1-bec4-619d1ed714ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1c8b2-a4c6-4cba-a7ed-027146777daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
