# Importar bibliotecas
import streamlit as st
import os
import google.generativeai as genai
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

# ‚úÖ Primeira chamada obrigat√≥ria do Streamlit
st.set_page_config(page_title="Chatbot - Brasil Participativo", page_icon="ü§ñ")

# T√≠tulo
st.title("ü§ñ Chatbot - Plataforma Brasil Participativo")

# Inicializa hist√≥rico da conversa
if "conversation" not in st.session_state:
    st.session_state.conversation = """
Voc√™ √© um assistente virtual especializado em participa√ß√£o social. Ao receber uma mensagem, sua tarefa √©:
1. Fornecer respostas claras e objetivas sobre participa√ß√£o social e sobre a plataforma Brasil Participativo.
2. Recomendar a participa√ß√£o social e, caso solicitado, sugira processos participativos abertos na plataforma Brasil Participativo.
3. N√£o comente sobre o documento fornecido.
4. Utilize informa√ß√µes do documento PDF carregado para enriquecer suas respostas quando relevante.
5. Seja educado!
"""

# Configurar a API da Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("gemini-1.5-flash")

# RAG: carregar e processar o PDF
vectorstore = None
if os.path.exists("FAQ.pdf"):
    try:
        loader = PyPDFLoader("FAQ.pdf")
        docs = loader.load()

        splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=500)
        chunks = splitter.split_documents(docs)

        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectorstore = FAISS.from_documents(chunks, embeddings)
    except Exception as e:
        st.error(f"Erro ao configurar RAG: {e}")
else:
    st.warning("Arquivo PDF 'FAQ.pdf' n√£o encontrado.")

# Interface de entrada
user_input = st.text_input("Digite sua d√∫vida sobre participa√ß√£o social e clique em Enviar:")

if st.button("Enviar") and user_input.strip():
    relevant_info = ""

    if vectorstore:
        try:
            docs = vectorstore.similarity_search(user_input, k=2)
            relevant_info = "\n\n".join([doc.page_content for doc in docs])
        except Exception as e:
            st.error(f"Erro ao buscar informa√ß√µes: {e}")

    full_prompt = st.session_state.conversation
    if relevant_info:
        full_prompt += f"\n\nInforma√ß√µes relevantes:\n{relevant_info}"

    try:
        response = model.generate_content([f"{st.session_state.conversation}\nUsu√°rio: {user_input}\nAssistente:", full_prompt])
        resposta = response.text
    except Exception as e:
        resposta = f"Erro ao gerar resposta: {e}"

    # Mostrar resposta
    st.write(f"**Assistente**: {resposta}")
    st.session_state.conversation += f"\nUsu√°rio: {user_input}\nAssistente: {resposta}"

    st.session_state.conversation += f"\nAssistente: {response}"



